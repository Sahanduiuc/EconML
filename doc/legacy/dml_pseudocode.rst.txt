API and Pseudocode for General Double ML Estimator
--------------------------------------------------

.. code-block:: python3
    :caption: Double ML CATE Estimator Class

    class DMLCateEstimator(LinearCateEstimator):

        def __init__(self, model_y, model_t, 
                        model_final=LinearRegression(fit_intercept=False),
                        featurizer=PolynomialFeatures(degree=1, include_bias=True)):
            ''' Initialize models and feature creator.
            
            Parameters
            model_y: (sklearn model) used to fit the regression of Y on X, W
            model_t: (sklearn model) used to fit the regression of T on X, W
            model_final: (sklearn linear model) used to fit the final regression
            featurizer: (sklearn preprocessor) used to create features ϕ(X) of X
                        in the final stage
            '''
            self.models_y = [clone(model_y), clone(model_y)]
            self.models_t = [clone(model_t), clone(model_t)]
            self.model_final = clone(model_final)
            self.featurizer = clone(featurizer)

        def fit(self, Y, T, X=None, W=None):
            ''' Fits a model of the heterogeneous constant marginal CATE based on
            the Double ML process.
        
            Parameters:
            Y: (n × d_y) matrix of outcomes for each sample
            T: (n × d_t) matrix of treatments for each sample
            X: optional (n × d_x) matrix of features for each sample
            W: optional (n × d_w) matrix of controls for each sample
            '''
            kf = KFold(n_splits=2)
            y_res = np.zeros(np.shape(Y))
            T_res = np.zeros(np.shape(T))
            for fid, (train_index, test_index) in enumerate(kf.split(X)):
                Y_train, Y_test = Y[train_index], Y[test_index]            
                T_train, T_test = T[train_index], T[test_index]
                X_train, X_test = X[train_index], X[test_index]            
                W_train, W_test = W[train_index], W[test_index]
                
                # Fit treatment model on co-variates from train data
                self.models_t[fid].fit((X_train, W_train), T_train)
                # Compute treatment residuals for test data
                T_res[test_index] = T_test - self.models_t[fid].predict((X_test, W_test))
                # Fit outcome model on co-variates from train data
                self.models_y[fid].fit((X_train, W_train), Y_train)
                # Compute outcome residuals for test data
                y_res[test_index] = Y_test - self.models_y[fid].predict((X_test, W_test))
            
            
            self.model_final.fit(product(T_res, self.featurizer.fit_transform(X)), y_res)

        
        def const_marginal_effect(self, X=None):
            ''' Calculates the constant marginal CATE θ(·) conditional on a vector of
                features on a set of m test samples {X_i}
            
                Parameters:
                X: optional (m × d_x) matrix of features for each sample
            
                Returns:
                theta: (m × d_y × d_t) matrix of constant marginal CATE of each treatment
                        on each outcome for each sample
            '''
            return self.model_final.predict(product(ones, self.featurizer.fit_transform(X)))
        
        @property
        def coef_(self):
            ''' Returns the sparse three dimensional tensor α, whose α[i,j,k] entry is the 
            coefficient associated with outcome i, treatment j and feature k'''
            return self.model_final.coef_.reshape(d_y, d_t, d_{phi(x)})
            
        def fitted_models_y(self):
            return self.models_y if fitted else raise error
        
        def fitted_models_t(self):
            return self.models_t if fitted else raise error
        
        def fitted_model_final(self):
            return self.model_final if fitted else raise error


.. code-block:: python3
    :caption: Sparse Linear Double ML CATE Estimator Class

    class MultiTaskWrapper(BaseEstimator):
        ''' This is a generic MultiTask wrapper for any sklearn base estimator.
        Essentially takes any estimator that is supposed to predict a 1-dimensional
        label y, and turns it into an estimator that predict a d-dimensional
        label y, produced by running d independent estimation problems for each
        output. This is mostly a utility class.
        '''

        def __init__(self, base_model):
            self.base_model = base_model
        
        def fit(self, X, Y):
            self.base_models = [clone(self.base_model).fit(X, Y[:, i]) 
                                    for i in range(Y.shape[1])]	
        
        def predict(self, X):
            return np.array([model.predict(X) for model in self.base_models]).T
        
        def	__getattr__(self, name):
            return [model.__getattr__(name) for model in self.base_models]
        
        def __setattr__(self, name, value):
            [model.__setattr__(name, value) for model in self.base_models]
        
    class SparseLinearDMLCateEstimator(DMLCateEstimator):
        ''' This is a specialization of the DMLCateEstimator to sparse linear models
        for the nuisance functions.
        '''
        
        def __init__(self, linear_model_y=LassoCV(), linear_model_t=LassoCV(), 
                        model_final=LinearRegression(fit_intercept=False),
                        featurizer=PolynomialFeatures(degree=1)):
            ''' Initialize models and feature creator.
            
            Parameters
            model_y: (sklearn linear model) used to fit the regression of each Y_i
                        on X, W, (X; W) ⊗ (ϕ(X); W)
            model_t: (sklearn linear model) used to fit the regression of T_i on X, W
            model_final: (sklearn linear model) used to fit the final regression
            featurizer: (sklearn preprocessor) used to create features ϕ(X) of X
                        in the final stage
            '''
            self.linear_model_y = linear_model_y
            self.linear_model_t = linear_model_t
            super().__init__(None, None, model_final, featurizer)
        
        def fit(self, Y, T, X=None, W=None):
            ''' Fits based on a sparse linear DML model. Builds the right composite models
            from the two base linear models that the user specified. The model for Y
            first transforms the data to add the cross product terms and then calls the base
            linear model on the transformed data for every coordinate of Y. For the model
            for T it calls the base estimator for every coordinate of T.
            '''
            def transform(XW, dX=X.shape[1]):
                return (XW; cross_product(XW, (XW[:dX], self.featurizer.fit_transform(XW[dX:])))) 
            
            self.model_y = Pipeline(transform, MultiTaskWrapper(clone(self.linear_model_y)))
            self.model_t = MultiTaskWrapper(self.linear_model_t)
            
            super().fit(Y, T, X, W)

